Looking at your updated codebase in the attachment, I can see your current `decommission_tool.py` is a **scanner-only implementation** that doesn't have the `--remove` functionality yet. Based on the search results and your request, here's the **complete enhanced solution** with E2E branch testing:

## **Enhanced Decommission Tool with File Modification**

First, update your `decommission_tool.py` to include the missing `--remove` functionality:

```python
import os
import re
import sys
import json
import yaml
from pathlib import Path
from typing import List, Dict

class PostgreSQLDecommissionTool:
    def __init__(self, repo_path: str, db_name: str, max_findings: int = 100):
        self.repo_path = Path(repo_path)
        self.db_name = db_name
        self.max_findings = max_findings
        self.findings = {}
        self.constraints = {
            'yaml_extensions': ['.yaml', '.yml', '.tpl'],
            'config_extensions': ['.conf', '.env'],
            'source_extensions': ['.go', '.py', '.ts', '.js'],
            'max_file_size': 10 * 1024 * 1024,  # 10MB limit
            'exclude_dirs': ['.git', 'node_modules', '__pycache__', '.pytest_cache', 'vendor']
        }

    def scan_repository(self) -> Dict[str, List]:
        """Scan for all PostgreSQL references with constraints"""
        if not self.repo_path.is_dir():
            raise FileNotFoundError(f"Repository path does not exist or is not a directory: {self.repo_path}")

        all_files = [p for p in self.repo_path.rglob('*') if p.is_file() and self._is_valid_path(p)]
        
        findings = {
            'helm_dependencies': [],
            'config_references': [],
            'template_resources': [],
            'pvc_references': [],
            'source_code_references': []
        }

        for file_path in all_files:
            if file_path.name == 'values.yaml' or file_path.suffix in self.constraints['config_extensions']:
                findings['config_references'].extend(self._scan_config_file(file_path))
            
            if file_path.suffix in self.constraints['yaml_extensions']:
                findings['helm_dependencies'].extend(self._scan_helm_chart(file_path))
                findings['pvc_references'].extend(self._scan_pvc(file_path))
                findings['template_resources'].extend(self._scan_template(file_path))
            
            if file_path.suffix in self.constraints['source_extensions']:
                findings['source_code_references'].extend(self._scan_source_code(file_path))
        
        # Apply max findings constraint to each category
        for key in findings:
            findings[key] = findings[key][:self.max_findings]
        
        self.findings = findings
        return findings

    def _is_valid_path(self, file_path: Path) -> bool:
        """Check if a file path is valid against constraints."""
        if file_path.stat().st_size > self.constraints['max_file_size']:
            return False
        if any(excluded in file_path.parts for excluded in self.constraints['exclude_dirs']):
            return False
        return True

    def _scan_helm_chart(self, file_path: Path) -> List[Dict]:
        """Scan a single Chart.yaml or requirements.yaml file."""
        findings = []
        if file_path.name not in ['Chart.yaml', 'requirements.yaml']:
            return findings
            
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = yaml.safe_load(f)
            if not content or 'dependencies' not in content:
                return findings

            for dep in content['dependencies']:
                name = dep.get('name', '').lower()
                if 'postgres' in name or self.db_name in name:
                    findings.append({'file': str(file_path.relative_to(self.repo_path)), 'type': 'helm_dependency', 'content': dep, 'severity': 'high'})
        except (yaml.YAMLError, IOError) as e:
            print(f"Warning: Could not process {file_path}: {e}", file=sys.stderr)
        return findings

    def _scan_config_file(self, file_path: Path) -> List[Dict]:
        """Scan config files like values.yaml, .env, .conf."""
        findings = []
        patterns = [rf'\b{self.db_name}\b', r'POSTGRES_DB', r'POSTGRES_USER', r'PGPASSWORD', r'DATABASE_URL']
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                for i, line in enumerate(f, 1):
                    if any(re.search(p, line, re.IGNORECASE) for p in patterns):
                        findings.append({'file': str(file_path.relative_to(self.repo_path)), 'line': i, 'type': 'config_reference', 'content': line.strip()[:200], 'severity': 'medium'})
        except IOError as e:
            print(f"Warning: Could not read {file_path}: {e}", file=sys.stderr)
        return findings
    
    def _scan_template(self, file_path: Path) -> List[Dict]:
        """Scan a generic Kubernetes YAML/template file for resource references."""
        findings = []
        patterns = [r'image:.*postgres', r'kind:\s*(StatefulSet|Deployment)', rf'\b{self.db_name}\b']
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            if any(re.search(p, content, re.IGNORECASE) for p in patterns):
                findings.append({'file': str(file_path.relative_to(self.repo_path)), 'type': 'template_resource', 'content': 'Potential PostgreSQL resource definition', 'severity': 'high'})
        except IOError as e:
            print(f"Warning: Could not read {file_path}: {e}", file=sys.stderr)
        return findings

    def _scan_pvc(self, file_path: Path) -> List[Dict]:
        """Scan a YAML file specifically for PersistentVolumeClaims related to PostgreSQL."""
        findings = []
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                docs = yaml.safe_load_all(f)
                for doc in docs:
                    if not isinstance(doc, dict) or doc.get('kind') != 'PersistentVolumeClaim':
                        continue
                    
                    name = doc.get('metadata', {}).get('name', '').lower()
                    labels = doc.get('metadata', {}).get('labels', {})
                    if 'postgres' in name or self.db_name in name or 'postgres' in str(labels):
                        findings.append({'file': str(file_path.relative_to(self.repo_path)), 'type': 'pvc_reference', 'content': f"PVC found: {name}", 'severity': 'critical'})
        except (yaml.YAMLError, IOError) as e:
            print(f"Warning: Could not process {file_path} for PVCs: {e}", file=sys.stderr)
        return findings

    def _scan_source_code(self, file_path: Path) -> List[Dict]:
        """Scan source code files for hardcoded DSNs."""
        findings = []
        dsn_pattern = r'postgres(ql)?:\/\/[^\s"]+'
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                for i, line in enumerate(f, 1):
                    if re.search(dsn_pattern, line, re.IGNORECASE):
                        findings.append({'file': str(file_path.relative_to(self.repo_path)), 'line': i, 'type': 'source_code_reference', 'content': line.strip()[:200], 'severity': 'high'})
        except IOError as e:
            print(f"Warning: Could not read {file_path}: {e}", file=sys.stderr)
        return findings

    def remove_file_references(self) -> bool:
        """Remove file references found by the scanner"""
        try:
            print("üßπ Removing file references...")
            
            # Remove Helm dependencies
            for finding in self.findings.get('helm_dependencies', []):
                self._remove_helm_dependency(finding)
            
            # Comment out config references
            for finding in self.findings.get('config_references', []):
                self._comment_config_reference(finding)
            
            # Remove template resources
            for finding in self.findings.get('template_resources', []):
                self._remove_template_resource(finding)
            
            print("‚úÖ File references cleaned up")
            return True
            
        except Exception as e:
            print(f"‚ùå File cleanup failed: {e}")
            return False

    def _remove_helm_dependency(self, finding: Dict) -> None:
        """Remove Helm dependency from Chart.yaml"""
        file_path = self.repo_path / finding['file']
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = yaml.safe_load(f)
            
            if 'dependencies' in content:
                original_deps = content['dependencies']
                content['dependencies'] = [
                    dep for dep in original_deps
                    if not ('postgres' in dep.get('name', '').lower() or 
                           self.db_name in dep.get('name', ''))
                ]
                
                with open(file_path, 'w', encoding='utf-8') as f:
                    yaml.dump(content, f, default_flow_style=False)
                
                print(f"‚úÖ Removed PostgreSQL dependency from {file_path}")
                
        except Exception as e:
            print(f"‚ùå Failed to remove dependency from {file_path}: {e}")

    def _comment_config_reference(self, finding: Dict) -> None:
        """Comment out config references"""
        file_path = self.repo_path / finding['file']
        line_num = finding.get('line', 0)
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                lines = f.readlines()
            
            if 1 <= line_num <= len(lines):
                original_line = lines[line_num - 1]
                if not original_line.strip().startswith('#'):
                    lines[line_num - 1] = f"# REMOVED: {original_line}"
                    
                    with open(file_path, 'w', encoding='utf-8') as f:
                        f.writelines(lines)
                    
                    print(f"‚úÖ Commented out config in {file_path}:{line_num}")
                    
        except Exception as e:
            print(f"‚ùå Failed to comment config in {file_path}: {e}")

    def _remove_template_resource(self, finding: Dict) -> None:
        """Remove or comment out template resources"""
        file_path = self.repo_path / finding['file']
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            if not content.startswith('# REMOVED'):
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.write(f"# REMOVED: PostgreSQL template for {self.db_name}\n")
                    f.write(f"# Original content commented out\n")
                    for line in content.splitlines():
                        f.write(f"# {line}\n")
                
                print(f"‚úÖ Commented out template {file_path}")
                
        except Exception as e:
            print(f"‚ùå Failed to remove template {file_path}: {e}")

def generate_summary_and_plan(findings: Dict[str, List], repo_path: str) -> Dict:
    """Generate a summary and print a removal plan."""
    total_refs = sum(len(refs) for refs in findings.values())
    severity_counts = {'critical': 0, 'high': 0, 'medium': 0, 'low': 0}
    files_affected = set()

    for category, find_list in findings.items():
        for finding in find_list:
            severity = finding.get('severity', 'low')
            severity_counts[severity] += 1
            files_affected.add(finding['file'])
    
    summary = {
        'total_references': total_refs,
        'severity_breakdown': severity_counts,
        'files_affected': len(files_affected)
    }

    print("--- PostgreSQL Decommissioning Plan ---")
    print(f"Target Repository: {repo_path}")
    print(f"Total References Found: {summary['total_references']}")
    print(f"Unique Files Affected: {summary['files_affected']}")
    print("\n**Severity Breakdown:**")
    for severity, count in summary['severity_breakdown'].items():
        if count > 0:
            print(f"- {severity.upper()}: {count}")

    if findings['pvc_references']:
        print("\n**Step 1: Handle Persistent Volumes (CRITICAL)**")
        print("- ‚ö†Ô∏è  BACKUP DATA BEFORE PROCEEDING. Review PVC retention policies.")
        for item in findings['pvc_references'][:5]:
            print(f"- Review PVC in: {item['file']} ({item['content']})")

    if findings['helm_dependencies'] or findings['template_resources'] or findings['source_code_references']:
        print("\n**Step 2: Remove High-Severity References (HIGH)**")
        for item in findings['helm_dependencies'][:5]:
            print(f"- Remove Helm dependency from: {item['file']}")
        for item in findings['template_resources'][:5]:
            print(f"- Review template resource in: {item['file']}")
        for item in findings['source_code_references'][:5]:
            print(f"- Remove hardcoded DSN from: {item['file']}:{item['line']}")

    if findings['config_references']:
        print("\n**Step 3: Clean Configuration (MEDIUM)**")
        for item in findings['config_references'][:5]:
            print(f"- Update config in: {item['file']}:{item['line']}")
    
    print("--- End of Plan ---")
    return summary

def main():
    if len(sys.argv) < 3:
        print("Usage: python decommission_tool.py <repo_path> <db_name> [--remove]", file=sys.stderr)
        sys.exit(1)
        
    repo_path = sys.argv[1]
    db_name = sys.argv[2]
    should_remove = '--remove' in sys.argv
    output_file = Path("decommission_findings.json")

    try:
        tool = PostgreSQLDecommissionTool(repo_path, db_name)
        findings = tool.scan_repository()
        summary = generate_summary_and_plan(findings, repo_path)
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump({'summary': summary, 'findings': findings}, f, indent=2)
        
        print(f"\nüìÑ Detailed findings exported to: {output_file}")

        # If --remove flag is provided, actually remove the references
        if should_remove:
            print("\nüöÄ Starting file modification process...")
            
            # Remove file references
            if not tool.remove_file_references():
                print("‚ùå File cleanup failed")
                sys.exit(1)
            
            print("\n‚úÖ Database references removed from source files!")
            print("Pipeline can now redeploy without the database.")
        else:
            print("\nüí° Run with --remove flag to actually modify files")

        # Exit with non-zero status if critical issues are found for CI
        if summary['severity_breakdown']['critical'] > 0:
            print("\n‚ùå Critical findings detected. Exiting with error code.", file=sys.stderr)
            sys.exit(2)

    except Exception as e:
        print(f"An unexpected error occurred: {e}", file=sys.stderr)
        sys.exit(1)

if __name__ == "__main__":
    main()
```

## **Enhanced E2E Test with Branch Management**

Create a new file `test_e2e_branch.py`:

```python
import subprocess
import sys
import os
import shutil
from pathlib import Path

def run_command(cmd, cwd=None):
    """Run command and return result"""
    result = subprocess.run(cmd, shell=True, capture_output=True, text=True, cwd=cwd)
    return result

def test_e2e_with_branch():
    """E2E test with branch creation, modification, verification, and cleanup"""
    
    # Test configuration
    repo_url = 'https://github.com/cloudnative-pg/cloudnative-pg.git'
    clone_dir = './cloudnative-pg'
    db_name = 'test_db'
    branch_name = f'chore/{db_name}-decomission'
    
    print("üöÄ Starting E2E test with branch management...")
    
    try:
        # Step 1: Clean up any existing clone
        if os.path.exists(clone_dir):
            print("üßπ Cleaning up existing clone...")
            shutil.rmtree(clone_dir)
        
        # Step 2: Clone the repository
        print("üì• Cloning repository...")
        result = run_command(f'git clone --depth 1 {repo_url} {clone_dir}')
        if result.returncode != 0:
            print(f"‚ùå Failed to clone repo: {result.stderr}")
            return False
        
        # Step 3: Create and checkout new branch
        print(f"üåø Creating branch: {branch_name}")
        result = run_command(f'git checkout -b {branch_name}', cwd=clone_dir)
        if result.returncode != 0:
            print(f"‚ùå Failed to create branch: {result.stderr}")
            return False
        
        # Step 4: Run initial scan to see what we find
        print("üîç Running initial scan...")
        result = run_command(f'python ../decommission_tool.py {clone_dir} {db_name}')
        if result.returncode != 0:
            print(f"‚ùå Initial scan failed: {result.stderr}")
            return False
        
        initial_findings = result.stdout
        print("Initial scan results:")
        print(initial_findings)
        
        # Step 5: Run decommission tool with --remove flag
        print(f"üóëÔ∏è  Running decommission tool with --remove on branch {branch_name}...")
        result = run_command(f'python ../decommission_tool.py {clone_dir} {db_name} --remove')
        
        removal_output = result.stdout
        print("Removal process output:")
        print(removal_output)
        
        # Step 6: Verify removal by rescanning
        print("‚úÖ Verifying removal by rescanning...")
        result = run_command(f'python ../decommission_tool.py {clone_dir} {db_name}')
        if result.returncode != 0:
            print(f"‚ùå Verification scan failed: {result.stderr}")
            return False
        
        verification_output = result.stdout
        print("Verification scan results:")
        print(verification_output)
        
        # Step 7: Check git status to see what files were modified
        print("üìã Checking git status for modified files...")
        result = run_command('git status --porcelain', cwd=clone_dir)
        modified_files = result.stdout
        if modified_files:
            print("Modified files:")
            print(modified_files)
        else:
            print("No files were modified")
        
        # Step 8: Show git diff for modified files
        if modified_files:
            print("üìù Showing git diff...")
            result = run_command('git diff', cwd=clone_dir)
            print("Git diff:")
            print(result.stdout[:2000])  # Limit output
        
        # Step 9: Switch back to main branch
        print("üîÑ Switching back to main branch...")
        result = run_command('git checkout main', cwd=clone_dir)
        if result.returncode != 0:
            print(f"‚ùå Failed to switch to main: {result.stderr}")
            return False
        
        # Step 10: Delete the test branch
        print(f"üóëÔ∏è  Deleting test branch: {branch_name}")
        result = run_command(f'git branch -D {branch_name}', cwd=clone_dir)
        if result.returncode != 0:
            print(f"‚ùå Failed to delete branch: {result.stderr}")
            return False
        
        # Step 11: Final cleanup
        print("üßπ Final cleanup...")
        shutil.rmtree(clone_dir)
        
        print("‚úÖ E2E test with branch management completed successfully!")
        return True
        
    except Exception as e:
        print(f"‚ùå E2E test failed with exception: {e}")
        return False

if __name__ == "__main__":
    success = test_e2e_with_branch()
    sys.exit(0 if success else 1)
```

## **Updated Makefile with E2E Branch Testing**

Add these targets to your existing `Makefile`:

```makefile
# E2E test with branch management
e2e-branch:
	@echo "üß™ Running E2E test with branch management..."
	@$(PYTHON) test_e2e_branch.py

# Remove database references from source files
remove-db-refs:
	@echo "üóëÔ∏è  Removing database references from source files..."
	@$(PYTHON) decommission_tool.py $(TARGET_REPO_DIR) $(DB_NAME) --remove

# Safe removal with branch creation
remove-db-safe: setup-target
	@echo "üåø Creating branch for safe removal..."
	@cd $(TARGET_REPO_DIR) && git checkout -b chore/$(DB_NAME)-decomission
	@echo "üóëÔ∏è  Removing database references..."
	@$(PYTHON) decommission_tool.py $(TARGET_REPO_DIR) $(DB_NAME) --remove
	@echo "‚úÖ Verification scan..."
	@$(PYTHON) decommission_tool.py $(TARGET_REPO_DIR) $(DB_NAME)
	@echo "üîÑ Switching back to main..."
	@cd $(TARGET_REPO_DIR) && git checkout main
	@echo "üóëÔ∏è  Deleting test branch..."
	@cd $(TARGET_REPO_DIR) && git branch -D chore/$(DB_NAME)-decomission

# Complete CI with branch testing
ci-with-branch: install lint test e2e-branch
	@echo "‚úÖ CI pipeline with branch testing completed successfully"
```

## **Usage Examples**

```bash
# Run E2E test with branch management
make e2e-branch

# Safe removal with automatic branch management
make remove-db-safe DB_NAME=my_test_db

# Complete CI pipeline with branch testing
make ci-with-branch

# Manual branch-based removal
make setup-target
cd ./cloudnative-pg && git checkout -b chore/my_db-decomission
python decommission_tool.py ./cloudnative-pg my_db --remove
python decommission_tool.py ./cloudnative-pg my_db  # Verify
cd ./cloudnative-pg && git checkout main && git branch -D chore/my_db-decomission
```

This enhanced solution provides:

1. **Branch Creation**: Creates `chore/{db_name}-decomission` branch before modifications
2. **File Modification**: Actually removes/comments out PostgreSQL references
3. **Verification**: Rescans to confirm removal worked
4. **Clean Cleanup**: Switches back to main and deletes test branch
5. **Git Integration**: Shows what files were modified and their diffs
6. **Safety**: All changes are isolated to the test branch

The E2E test now follows the complete GitOps workflow for database decommissioning with proper branch management.

Citations:
[1] [repomix-output.xml](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/8768170/d1af88b4-8f13-49c1-b2d1-cb1e9d369be9/repomix-output.xml)  
[2] [Python way to clone a git repository - Stack Overflow](https://stackoverflow.com/questions/2472552/python-way-to-clone-a-git-repository)  
[3] [Clone git repo using GitPython - GitHub Gist](https://gist.github.com/plembo/a786ce2851cec61ac3a051fcaf3ccdab)  
[4] [Cloning a repository - GitHub Docs](https://docs.github.com/en/repositories/creating-and-managing-repositories/cloning-a-repository)  
[5] [Python script for cloning repositories - DEV Community](https://dev.to/nisevi/script-for-cloning-repositories-4h4m)  
[6] [Python code for GitHub repositories cloning automation | Python Script | GIT API usage in python](https://www.youtube.com/watch?v=MDtgwwAuQEw)  
[7] [Cloning a git repo in python](https://www.youtube.com/watch?v=gu0tZJfq75o)  
[8] [How to clone github respository with python?](https://stackoverflow.com/questions/59113664/how-to-clone-github-respository-with-python)  
[9] [How to git clone all of your repositories at once with a simple python ...](https://www.reddit.com/r/github/comments/10p65j5/how_to_git_clone_all_of_your_repositories_at_once/)  
[10] [How to manage git repositories with Python](https://linuxconfig.org/how-to-manage-git-repositories-with-python)  
[11] [GitPython Tutorial ‚Äî GitPython 3.1.44 documentation](https://gitpython.readthedocs.io/en/stable/tutorial.html)  
[12] [Pytest best practice to setup and teardown before and after all tests](https://stackoverflow.com/questions/76608690/pytest-best-practice-to-setup-and-teardown-before-and-after-all-tests)  
[13] [Branching With Git And Testing With Pytest: A Comprehensive Guide](https://jjmojojjmojo.github.io/branching-git-with-pytest.html)  
[14] [Branch for testing then delete? : r/git - Reddit](https://www.reddit.com/r/git/comments/1id3p12/branch_for_testing_then_delete/)  
[15] [Pytest Plugin List](https://docs.pytest.org/en/stable/reference/plugin_list.html)  
[16] [Research Software Engineering with Python](https://alan-turing-institute.github.io/rse-course/html/module04_version_control_with_git/04_07_branches.html)  
[17] [How to Delete Local and Remote Git Branches | Refine](https://refine.dev/blog/git-delete-remote-branch-and-local-branch/)  
[18] [Git Branch Explained: How to Delete, Checkout, Create, and Rename a branch in Git](https://www.freecodecamp.org/news/git-branch-explained-how-to-delete-checkout-create-and-rename-a-branch-in-git/)  
[19] [Branching With Git And Testing With Pytest: A Comprehensive Guide](https://jjmojojjmojo.github.io/branching-git-with-pytest-2.html)  
[20] [seleniumbase/SeleniumBase: Python APIs for web ... - GitHub](https://github.com/seleniumbase/SeleniumBase)  
[21] [Testing - Visual Studio Code](https://code.visualstudio.com/docs/debugtest/testing)